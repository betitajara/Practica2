---
title: 'Práctica 2: Limpieza y Validación de los Datos'
author: "Beatriz Elena Jaramillo Gallego"
date: "08 de Mayo de 2018"
output: pdf_document
---

---
bibliography: referencias.bib
csl: estilo.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#librerias
library("knitr")
library("dplyr")              #   Para usar join
library("VIM")
library("gridExtra")
library("tinytex")
library("grDevices")
library("ggfortify")
library("corrplot")
library("psych")            #   Para usar pca
library("e1071")            #   Para usar SVM
library("rpart")            #   Para hacer uso de Arboles de Decision
library("rpart.plot")       #   Para imprimir los Arboles de Decision
library("arules")           #   Para utilizar Reglas de Asocacion
library("arulesViz")        #   Para visualizar correctamente las R. A.
library("FactoMineR")       #   Para realizar el analisis exploratorio de datos
library("ggplot2")          #   Para graficos de mejor calidad
library("GGally")
library("ape")              #   Para visualizacion de graficos de arboles mejorados
library("party")            #   Para la generacion de Arboles de decision
library("survival")           #   Para Análisis de superviviencia
library("KMsurv")
library("survMisc")
library("survminer")
library("flexsurv")
library("actuar")
```

\renewcommand{\baselinestretch}{1.1}

\tableofcontents 

\newpage

# Detalles de la actividad 

## Descripción

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

\begin{itemize}
\item Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
\item Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.
\end{itemize}

## Objetivos

Los objetivos concretos de esta práctica son:

\begin{itemize}
\item  Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
\item  Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico. 
\item  Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
\item  Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
\item  Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
\item  Desarrollar las habilidades de aprendizaje que les permitan continuarestudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
\item  Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

\end{itemize}

\newpage

# Resolución Práctica

## 1. Descripción del dataset 

Los datos para el análisis se ha obtenido a partir de este enlace en Kaggle Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic) y está constituido por 12 (variables) que presentan 891 pasajeros(filas o registros) en el archivo de train y 418 pasajeros(filas o registros) en el archivo de test.

Los datos se han dividido en dos grupos:
\begin{itemize}
\item Conjunto de entrenamiento (train.csv): El conjunto de entrenamiento se debe usar para construir sus modelos de aprendizaje automático
\item Conjunto de prueba (test.csv): El conjunto de prueba se debe usar para ver qué tan bien se desempeña su modelo en datos no vistos.
\end{itemize}

__Variables__
\begin{itemize}
\item  PassengerId: Un identificador numerico del pasajero. Es una variable númerica.
\item  Survived: Varibale binaria donde se indica si el pasajero sobrevivio o no. (0 = No, 1 = Yes)
\item  Pclass: La clase en la que viajaba el pasajero. Es una variable númerica. (1 = 1st, 2 = 2nd, 3 = 3rd)
\item  Name: El nombre del pasajero. Es una variable nominal.
\item  Sex: El sexo del pasajero. Es una varuable nominal.
\item  Age: La edad del pasajero. Es una variable númerica.
\item  SibSp: Numero de familiares cosanguineos de la persona abordo del Titanic. Es una variable númerica
\item  Parch: Numero de familaires de diferente grado que acompañaban a la persona abordo del Titanic. Es una variable númerica
\item  Ticket: El ticket correspondiente al pasajero al momento del abordaje. Es una variable nominal.
\item  Fare: La tarifa del ticket segun la clase en la que abordo el pasajero. Es una variable númerica
\item  Cabin: El identificador de la cabina que utilizo la persona durante el viaje. Es una variable nominal
\item  Embarked: Indica el lugar de embarque de la persona. Es una variable nominal. (C = Cherbourg, Q = Queenstown, S = Southampton)
\end{itemize}

__Pregunta/problema pretende responder__
Problema: Podria llegarse a determinar/predecir la superviviencia de los pasajeros del Titanic?
Para reponder el anterior problema se dede tener en cuenta las caracteristicas como edad, sexo y la tarifa del ticket según la clase en la que abordo el pasajero. Después de realizar un análisis de superviviencia podré responder esta pregunta.

__Notas Variables__
Pclass: un proxy para el estado socio-económico (SES)
1er = superior
2do = Medio
Tercero = Más bajo

Sibsp: el conjunto de datos define las relaciones familiares de esta manera ...
Hermano = hermano, hermana, hermanastro, hermanastra
Cónyuge = esposo, esposa (las amantes y los novios fueron ignorados)

Parch: El conjunto de datos define las relaciones familiares de esta manera ...
Padre = madre, padre
Niño = hija, hijo, hijastra, hijastro
Algunos niños viajaban solo con una niñera, por lo tanto parch = 0 para ellos.

\newpage

## 2. Integración y selección
__Integración y selección de los datos de interés a analizar.__

Hare un vistazo genereal de como llegan los datos en el dataset train, el cual tiene las 12 variables anteriormente descritas.
```{r train}
#setwd("C:/Users/Admin/Dropbox/Master/Tipologia de Datos/PRACTICA 2")
titanic <- read.csv2("train.csv",header = TRUE,sep = ";",dec = ",",stringsAsFactors=FALSE)
cat(paste0("Carga fichero train.csv OK.","\n\n"))
str(titanic)
```

Variables Categoricales: Survived, Sex, and Embarked. Ordinal: Pclass.

Variables Continuas: Age, Fare. Discrete: SibSp, Parch

Las Variables Cabin, Ticket y PassengerId son informativas y serán usasdas en el análisis.

Haciendo algún tratamiento de datos. La variable __Fare__ debe ser numerica y se encuentra como factor, la he convertido en numerica.

```{r}
titanic$Name <- as.factor(titanic$Name)
titanic$Sex <- as.factor(titanic$Sex)
titanic$Ticket <- as.factor(titanic$Ticket)
titanic$Embarked <- as.factor(titanic$Embarked)
titanic$Age <- as.numeric(titanic$Age)
titanic$Fare <- as.numeric(titanic$Fare)

summary(titanic)
```

\newpage

## 3. Limpieza de los datos

### 3.1. Ceros y elementos vacíos

¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Hay 263 datos __NA__ en la variable Age, hay 418 NA en la variable __Survived__, que son los valores que anteriormente adicione del dataset test.

```{r}
# Números de valores desconocidos por campo
sapply(titanic, function(x) sum(is.na(x)))

cat("\n\n")
cat(paste0("Valores vacios Age ",round((177/891)*100,2)),"%")
cat("\n\n")

cat(paste0("Valores vacios Fare ",round((15/891)*100,2)),"%")
cat("\n\n")
```

```{r}
# Para aquellos pasajeros que se desconoce la cabina, se le cambia su vacio  por un string que indica desconocido
titanic$Cabin[titanic$Cabin==""] <- "Unknown"
titanic$Cabin <- as.factor(titanic$Cabin)

# Hay 2 pasajeros en la columna Embarked que estan vacios y la mayoria embarco por S entonces lo he agregardo alli.
errores = which(titanic$Embarked=="")
titanic$Embarked[errores] = "S"
titanic$Embarked <- factor(titanic$Embarked)
rm(errores)
```

Para manejar los registros que contienen valores desconocidos para algún campo, una opción podría ser eliminar los registros que incluyen este tipo de valores de la variable Age, pero ello supondría desaprovechar el 19.87% de esta información y para la varaible Fare quitar los NA upondría desaprovechar el 1.68% de esta información

Se empleará el método para imputa de una manera sofisticada para que no toda la matriz de distancia tenga que calcularse: la imputación basada en k vecinos más próximos (en inglés, kNN-imputation). Por lo tanto, la implementación del paquete VIM también es aplicable para conjuntos de datos razonablemente grandes

```{r imputacion}
# Imputación de valores mediante la función kNN() del paquete VIM
suppressWarnings(suppressMessages(library(VIM)))
titanic$Age <- kNN(titanic)$Age
titanic$Fare <- kNN(titanic)$Fare
sapply(titanic, function(x) sum(is.na(x)))
summary(titanic)
```

### 3.2. Valores extremos
__Identificación y tratamiento de valores extremos__

Los valores extremos o outliers son aquellos que parecen no ser congruentes sin los comparamos con el resto de los datos.

```{r}
ggpairs(titanic[c(2,3,6,7,8,10)])
```

```{r}
#gráfico la variable Age, sin NA
ggplot(titanic, aes(x = Age)) +
    geom_histogram(fill = "darkblue", alpha = .5) +
    geom_histogram(colour = "black")+
    facet_wrap(~ Survived)
```

```{r}
boxplot.stats(titanic$Age)$out
```

```{r}
#gráfico la variable Fare
ggplot(titanic, aes(x = Fare)) +
    geom_histogram(fill = "darkblue", alpha = .5) +
    geom_histogram(colour = "black")+
    facet_wrap(~ Survived)
```

```{r}
boxplot.stats(titanic$Fare)$out
```

```{r}
p <- ggplot(titanic, aes(x=Survived, y=Age,fill=Survived)) + 
    geom_boxplot() 
q <- ggplot(titanic, aes(x=Survived, y=Fare,fill=Survived)) + 
    geom_boxplot() 

grid.arrange(p,q,ncol = 2)
```

En este caso los datos atipicos surgen de un error de procedimiento, tales como la entrada de datos o un error de codificacion. Estos casos atipicos deberan subsanarse en el filtrado de los datos, y si no se puede, deberan eliminarse del analisis o recodificarse como datos ausentes.

Estos datos "atipicos" los dejare como están ya que los he filtrado y estos pasajeros son los que viajan en Primera Clase y 5 casos que viajan en 2 clase y el valor de su pasaje concuerda.

Cuando termine de realizar el análisis sin quitar estos datos, realizare un análisis similar y quitare estos datos para posteriormente hacer una comparación y concluir si estos 108 casos tienen un valor significante en este análisis, pero a prioro podría decirse que tiene un valor significativo ya que se sabe que las personas de 1 clase son las que tenian mayor posibilidad de sobrevivir con respecto a las demás clases.
```{r}
length(boxplot.stats(titanic$Fare)$out)
ati_class1 <- filter(titanic, titanic$Fare >=66)
head(ati_class1)
```

Otras variables númericas que se utilizan en el problema.

```{r}
# La cantidad de personas en cada clase
p <- ggplot(titanic, aes(x=Pclass)) + 
  geom_histogram()

# La cantidad hermanos/conyuges de la personas
r <- ggplot(titanic, aes(x=SibSp)) + 
  geom_histogram()

# La cantidad de parientes y niños abordo 
s <- ggplot(titanic, aes(x=Parch)) + 
  geom_histogram()

# La tarifas de los tickets por personas
t <- ggplot(titanic, aes(x=Fare)) + 
  geom_histogram()

grid.arrange(p,r,s,t,ncol = 2)
```

\newpage

## 4. Análisis de los datos.

### 4.1. Selección de los grupos de datos a analizar
__Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)__

Los métodos estadísticos utilizado en el análisis de supervivencia frecuentemente presentan cierta complejidad en los cálculos, esto debido a la naturaleza de las observaciones las cuales suelen presentar censura y/o truncamiento. La utilización de software estadístico para realizar dicho análisis se ha vuelto indispensable en la práctica.

__Estimador de Kaplan-Meier y Fleming-Harrington__

Los estimadores de Kaplan-Meier y Fleming-Harrington para la función de supervivencia es obtenido a través paquete estadístico survival mediante la función survfit(). Esta función en su forma más sencilla, solo requiere un objeto de supervivencia creado por la función Surv(). Los argumentos de la función survfit() son los siguientes:

\begin{enumerate}
\item formula. Un objeto fórmula y ~ x, que debe tener un objeto Surv como variable respuesta a la izquierda del " ~ " y, si se desea, el nombre de las covariables por la derecha. Uno de los términos puede ser un objeto estrato. Para una sola curva de supervivencia del lado derecho se coloca ~1.
\item data. objeto data frame donde están los datos.
\item type. Tipo de estimador: “kaplan-meier” o “fleming-harrington”.
\end{enumerate}
    
__Arboles de Decision__
Un Árbol de Decisión es un modelo de predicción utilizado para modelar construcciones lógicas sobre el contenido de bases de datos, para la toma decisiones en base a esas entradas, es decir, es una forma gráfica y analítica de representar todos los eventos que pueden surgir a partir de una decisión asumida en cierto momento. Estoy comenzando a comprender esta herramienta estadística, toda vez que un heterogéneo conjunto de variables condicionan los resultados clínicos de nuestros pacientes y nos pueden ayudar a entender mejor el proceso de salud enfermedad, sobre todo en el área de la patología y medicina oral.

### 4.2. Normalidad
__Comprobación de la normalidad y homogeneidad de la varianza.__

Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población con distribución normal, utilizaremos la prueba de normalidad de Anderson-Darling.

Con esto, comprobaremos que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado alpha = 0, 05. Si esto se cumple, entonces se considera que la variable se distribuye normalmente.

(He incluido Age y Fare, ya que despuès de haber hecho las correcciones pertinentes porque estas varibles son también numéricas)
```{r}
library(nortest)
alpha = 0.05
col.names = colnames(titanic)
for (i in 1:ncol(titanic)) {
    if (i == 1) cat("Variables que no se distribuyen normalmente:\n")
    if (is.integer(titanic[,i]) | is.numeric(titanic[,i])) {
        p_val = ad.test(titanic[,i])$p.value
        if (p_val < alpha) {
            cat(col.names[i])
            # Format output
    if (i < ncol(titanic) - 1) cat(", ")
        }
    }
}
```
Luego se estudia la homogeneidad de varianzas mediante la aplicación del test de Fligner-Killeen. En este caso, estudiaremos esta homogeneidad en cuanto a los grupos conformados por las edades de los pasajeros que han o no sobrevivido. En el siguiente test, la hipótesis nula consiste en que ambas varianzas son iguales.

```{r}
fligner.test(Age ~ Survived, data = titanic)
```
Puesto que obtenemos un p-valor superior a 0,05, aceptamos la hipótesis de que las varianzas de ambas muestras son homogéneas.

```{r}
par(mfrow=c(1,2))
qqnorm(titanic$Age); qqline(titanic$Age)
# p-plot: you should observe a good fit of the straight line
probplot(titanic$Age, qdist=qnorm)
```
Las desviaciones de la línea recta son leves. Esto indica una distribución normal.

El histograma:
```{r}
# Let's overlay a PDG on a histogram of age
ggplot(titanic, aes(x=Age)) + 
    ggtitle("Passenger Age") + 
    xlab("Age") + 
    ylab("Density") + 
    geom_histogram(aes(y=..density..), binwidth=1)+
    geom_density(alpha=.5, fill="#FFFFFF")
```

### 4.3. Pruebas Estadísticas
__Aplicación de pruebas estadísticas para comparar los grupos de datos__

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc.

Ahora poseemos un mejor conocimiento de los elementos y atributos de las variables, pero esta no nos dicen la manera en que se relacionan. Para ello apliacaremos un analisis de componentes principales al conjunto de datos.
 
__Correlación entre variables__
En primer lugar, procedemos a realizar un análisis de correlación entre las distintas variables
para determinar cuáles de ellas ejercen una mayor influencia sobre la superviviencia.
Para ello, se utilizará el coeficiente de correlación de Spearman, puesto que hemos visto que
tenemos datos que no siguen una distribución normal.
 
```{r}
#variables cuantitativas
cuant <- data.frame(
    titanic$Survived,titanic$Pclass,titanic$Age,titanic$Parch,titanic$SibSp,titanic$Fare)
#   Cuales varaibles parecieran tener alguna relacion entre si
M <- cor(cuant)
round(M,2)
#Correlación
corrplot.mixed(M, lower.col = "black", number.cex = .7)

```

Las variables Survived con Pclass y Fare estan altamente correlacionadas.

#### Regresión Lineal
Podría resultar útil realizar predicciones sobre la supervivencia de los pasajeros del Titanic dadas las varaibles que tenemos a nuestra disposición. Calcularé un modelo de regresión lineal utilizando regresores tanto cuantitativos como cualitativos con el que poder realizar las predicciones para predecir la supervivencia y ver el peso y sentido de cada una de las variables.

```{r regresion_lineal}
(gender_model <- lm(Survived~Sex, data=titanic))
summary(gender_model)$r.squared
```

Este modelo predice que las mujeres tienen un 74.2% de supervivencia y los hombres tienen un 74.2 - 55.3 = 18.9% de probabilidad de supervivencia.

Haremos una regesión lineal con todas las variables.

```{r regresion_lineal2}
(gender_model2 <- lm(Survived~Pclass+Sex+Age+SibSp+Parch+Fare+Embarked, data=titanic))
summary(gender_model2)$r.squared
```

Luego utilizando las variables que estén más correlacionadas con respecto a Survived. Así, de entre todos los modelos que tengamos, escogeremos el mejor utilizando como criterio aquel que presente un mayor coeficiente de determinación (R2).

```{r regresion_lineal3}
(gender_model3 <- lm(Survived~Pclass+Fare, data=titanic))
summary(gender_model3)$r.squared
```

Vemos que habian 313 mujeres y 578 hombres lo que representa un 35,13% de mujeres y un 64,87% de hombres en el conjunto de entrenamiento. Ahora relacionemos esta información con la sobrevivencia de los pasajeros y tambien la tasa de sobrevivencia de los niños.

```{r}
#   Con respecto al Sexo de las personas podemos ver la siguiente distribucion
table(titanic$Sex)
```

```{r}
#   Siguiendo el contexto del problema examinemos el sexo de los sobrevivientes
table(titanic$Sex,titanic$Survived)
Surv_age <- ifelse(titanic$Age<=18,"Niño","Adulto") 
table(Surv_age,titanic$Survived)
table(Surv_age,titanic$Survived, by=titanic$Sex) # Sobrevivieron mas niñas que niños
```

Ahora comparemos usando arboles decision como metodo para generar un modelo predictivo.

```{r}
#   Tomamos un subconjunto de los mismos
titanic2 <- subset(titanic,select=-c(PassengerId,Name,Ticket,Cabin))
modelo_arbol <- rpart(Survived ~ ., data=titanic2,method="class")
#arbol de decisión
rpart.plot(modelo_arbol)

prediction <- predict(modelo_arbol,titanic2[,-1])
prediction <- ifelse(prediction<0.5,0,1)
matriz_conf <- table(prediction = prediction[,2], true = titanic2[,1])
matriz_conf
```

De acuerdo a la matriz de confusión tenemos el mismo indice de acierto y de desacierto que teniamos inicialmente, con una pequeña variacion entre falsos positivos y falsos negativos. 

__Análisis de supervivencia__

```{r}
flex <- flexsurvreg(Surv(Age,Survived) ~ 1, data = titanic, dist = "exp")  #Ajuste exponencial
flex

# Guardando el Objeto Surv
titanic.surv <- Surv(titanic$Age,titanic$Survived)  #Creando objeto tipo Surv
titanic.km <- survfit(titanic.surv ~ 1, data = titanic, type = "kaplan-meier")  #Estimación Kaplan Meier
summary(titanic.km)
```

La estimación devuelve los siguientes valores:

- time : Tiempo de la observación
- n.risk : El número de sujetos en riesgo.
- n.evento : El número de sujetos que presentaron el evento.
- survival : La estimación de la función de supervivencia.
- std.err : La desviación estándar de la estimación.
- lower y upper CI* : Los intervalos de confianza para la estimación.

La función survfit() devuelve un resumen de la estimación, la información se puede acceder agregando el símbolo “$” seguido del nombre del elemento de la lista.

Una mejor manera de extraer la información es utilizando la función fortify() sobre el objeto survfit, esta función devuelve un data.frame con la información. Al tener presencia de covariables se anexa la columna llamada strata.

```{r}
# Ahora veamos la tasa de supervivencia de las personas segun la clase con la
# que abordaron
table(titanic$Survived,titanic$Pclass)
```
Ciertamente, los pasajeros de primera clase tienen un indice de sobrevivencia claramente mas alto que las otras dos clases. Los pasajeros de segunda clase tenian casi la misma proporcion de pasajeros vivos y muertos y la tercera clase esta claramente en desventaja a la hora de poder alcanzar un bote salvavidas.

__Desviación estándar e Intervalos de confianza de la estimación de la función de supervivencia__

Tanto como la desviación estándar y los Intervalos de confianza de la curva de supervivencia es estimada mediante la función survfit() con los siguientes argumentos:

- error: Tipo de estimación para las desviaciones, los posibles valores son “greenwood”(defecto) para la fórmula de Greenwodd o “tsiatis” para la fórmula de Tsiatis/Aalen.
- conf.type: Tipo de transformación para calcular los intervalos de confianza, “plain”, “log”(defecto), *“log-log”.
- conf.int: El nivel de confianza para el intervalo de confianza (.95 por defecto).

```{r}
titanic.km <- survfit(Surv(Age,Survived) ~ 1, data = titanic, type = "kaplan-meier", 
    error = "tsiatis", conf.type = "log-log", conf.int = 0.99)

summary(titanic.km)
```

\newpage

## 5. Visualización
__Representación de los resultados a partir de tablas y gráficas__

```{r}
counts = table(titanic$Survived, titanic$Sex)
barplot(counts, 
        main = "Titanic Survival Counts by Passenger Sex",
        xlab = "Passenger Sex", 
        ylab = "Count",
        col = topo.colors(2),  
        beside = TRUE)

legend("topleft", 
       inset =.03,
       legend = c("died", "survived"), 
       fill = topo.colors(2), 
       horiz = TRUE)

# STACKED BAR CHART WITH COLORS AND LEGEND
counts = table(titanic$Survived, titanic$Pclass)

# CONSTRUCT BARCHART
barplot(counts, 
        main = "Titanic Survival Rates by Passenger Class",
        xlab = "Passenger Class", 
        col = terrain.colors(2))

# ADD LEGEND
legend("topleft", 
       inset = .03,
       legend = c("died", "survived"), 
       fill = terrain.colors(2), 
       horiz = TRUE)
```

__Graficación de la curva de supervivencia__

La curva de supervivencia estimada se gráfica con la función ggsurvplot() de la paquetería survminer, está gráfica esta hecha utilizando la librería ggplot2 y contiene un numero grande de parámetros, por lo que solamente ilustraremos los más importantes y se recomienda revisar los demás utilizando el comando help("ggsurvplot").

- fit: Objeto tipo survfit.
- data: Un conjunto de datos utilizado para ajustar curvas de supervivencia.
- fun: Transformación de la curva de supervivencia(Opcional), las posibles opciones son: “event” para los eventos acumulados, “cumhaz” para el riesgo acumulado y “pct” para la curva de supervivencia en porcentaje.
- conf.int: Indicador para graficar los intervalos de confianza.
- title: Titulo
- xlab: Eje x
- ylab: Eje Y
- legends.lab: Vector de nombres para identificar las curvas.
- legend.title : Titulo de la leyenda.
```{r}
ggsurvplot(fit = titanic.km, data = titanic, conf.int = T, title = "Curva de Supervivencia", 
    xlab = "Tiempo", ylab = "Probabilidad de supervivencia", legend.title = "Estimación", 
    legend.labs = "Kaplan-Meier")
```

__Guardar fichero final__
```{r}
write.csv(titanic, file = "titanic.csv")
```

\newpage

## 6. Resolución del problema. 

- Con el análisis de correlación pude conocer cuáles de las variables inicales variables ejercen una mayor influencia para analizar/predecir la superviviencia de los pasajeros del titanic.

- Se ha hecho un preprocesamiento para manejar los casos de ceros o elementos vacíos y valores extremos (outliers). Hice una imputación de datos faltantes en las variables Age y Fare y así conservamos la totalidad de los datos y no eliminamos registros del conjunto de datos inicial.

- Los datos outliers los he conservado porque he comprobado que la variable Fare pertenece a personas que pagaron un ticket de primera clase.

- Podmemos concluir que en efecto, mas pasajeros mujeres que hombres sobrevivieron, por lo que podemos establecer una prioridad a la hora del abordaje de los botes salvavidas. Con los niños no fue tanto el caso. La proporción esta mas equilibrada casi al punto de que la la mitad de los niños y las niñas sobrevivieron, con una leve inclinacion a la proporcion en los niños.

- Con los árboles de decisión y usando los pasajeros el Titánic, obtendremos que aquellos individuos que murieron y que no murieron presentaron diferencias, y la regresión logística lo que hará será detectar estas diferencias entre el desenlace de muerte/sobrevida y entre ellas mismas. Al final la máquina nos dirá cuáles fueron las más poderosas, y el investigador podrá decir y darle un número a cada una de ellas para crear un algoritmo o regla con puntos o valores para cada variable. Por ejemplo, darle 2 puntos a ser de primera clase, 1 punto al sexo, 1 a la edad, etc.

- Como pueden notar, no existe UNO solo que sea un factor infalible a la hora de predecir sobrevida. Habrá algunos más fuertes que otros; por ejemplo, ser de primera clase es el factor más fuerte y predictor de sobrevida, aunque no es garantía (ya que murieron 4 personas, incluyendo una niña de 4 años de primera clase). Pero si eres menor de 10 años, niña, y en primera clase, tus probabilidades se irán al casi 100% de supervivencia y de que llegues a Nueva York sano y salvo.


## 7. Código

El código de la práctica esta implicito en cada uno de los chunck del reporte.

\newpage

#Referencias

Los siguientes recursos son de utilidad para la realización de la práctica:

- Megan Squire (2015). Clean Data. Packt Publishing Ltd.
- Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann
- Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369
- Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media
- Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc
- Tutorial de Github "https://guides.github.com/activities/hello-world"
- Ejemplos de contrastes de hipótesis con R:  " https://rstudio-pubs-static.s3.amazonaws.com/65042_a1784120e81a430f9de400ed9b899b0b.html"
- Tutorial dplyr:  "https://github.com/fdelaunay/tutorial-dplyr-es/blob/master/R/tutorial-dplyr.md"
- Test de Shapiro-Wilk:  "https://rpro.wikispaces.com/Test+de+Shapiro-Wilk"
- Estadística descriptiva: "Introducción al análisis de datos", Àngel J. Gil Estallo
- Intervalos de confianza, Àngel J. Gil Estallo
- Contrastes de hipótesis, Carles Rovira Escofet
- Contraste de dos muestras, Josep Gibergans Bàguena                                      
