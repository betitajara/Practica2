---
title: 'Práctica 2: Limpieza y validación de los datos'
author: "Beatriz Elena Jaramillo Gallego"
date: "08 de Mayo de 2018"
output: pdf_document
---

---
bibliography: referencias.bib
csl: estilo.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#librerias
library("knitr")
library("dplyr")              #   Para usar join
library("VIM")
library("grDevices")
library("ggfortify")
library("corrplot")
library("gridExtra")
library("ggbiplot")
library("psych")            #   Para usar pca
library("e1071")            #   Para usar SVM
library("rpart")            #   Para hacer uso de Arboles de Decision
library("rpart.plot")       #   Para imprimir los Arboles de Decision
library("arules")           #   Para utilizar Reglas de Asocacion
library("arulesViz")        #   Para visualizar correctamente las R. A.
library("FactoMineR")       #   Para realizar el analisis exploratorio de datos
library("ggplot2")          #   Para graficos de mejor calidad
library("GGally")
library("ape")              #   Para visualizacion de graficos de arboles mejorados
library("party")            #   Para la generacion de Arboles de decision
```

\renewcommand{\baselinestretch}{1.1}

\tableofcontents 

\newpage

# Detalles de la actividad 

## Descripción

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

\begin{itemize}
\item Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
\item Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.
\end{itemize}

## Objetivos

Los objetivos concretos de esta práctica son:

\begin{itemize}
\item  Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
\item  Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico. 
\item  Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
\item  Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
\item  Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
\item  Desarrollar las habilidades de aprendizaje que les permitan continuarestudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
\item  Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

\end{itemize}

\newpage

# Resolución Práctica

## 1. Descripción del dataset 

¿Por qué es importante y qué pregunta/problema pretende responder?

Los datos para el análisis se ha obtenido a partir de este enlace en Kaggle Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic) y está constituido por 12 (variables) que presentan 891 pasajeros(filas o registros) en el archivo de train y 418 pasajeros(filas o registros) en el archivo de test.

Los datos se han dividido en dos grupos:
\begin{itemize}
\item Conjunto de entrenamiento (train.csv): El conjunto de entrenamiento se debe usar para construir sus modelos de aprendizaje automático
\item Conjunto de prueba (test.csv): El conjunto de prueba se debe usar para ver qué tan bien se desempeña su modelo en datos no vistos.
\end{itemize}

__Variables__
\begin{itemize}
\item  PassengerId: Un identificador numerico del pasajero. Es una variable númerica.
\item  Survived: Varibale binaria donde se indica si el pasajero sobrevivio o no. (0 = No, 1 = Yes)
\item  Pclass: La clase en la que viajaba el pasajero. Es una variable númerica. (1 = 1st, 2 = 2nd, 3 = 3rd)
\item  Name: El nombre del pasajero. Es una variable nominal.
\item  Sex: El sexo del pasajero. Es una varuable nominal.
\item  Age: La edad del pasajero. Es una variable númerica.
\item  SibSp: Numero de familiares cosanguineos de la persona abordo del Titanic. Es una variable númerica
\item  Parch: Numero de familaires de diferente grado que acompañaban a la persona abordo del Titanic. Es una variable númerica
\item  Ticket: El ticket correspondiente al pasajero al momento del abordaje. Es una variable nominal.
\item  Fare: La tarifa del ticket segun la clase en la que abordo el pasajero. Es una variable númerica
\item  Cabin: El identificador de la cabina que utilizo la persona durante el viaje. Es una variable nominal
\item  Embarked: Indica el lugar de embarque de la persona. Es una variable nominal. (C = Cherbourg, Q = Queenstown, S = Southampton)
\end{itemize}

__Notas Variables__
Pclass: un proxy para el estado socio-económico (SES)
1er = superior
2do = Medio
Tercero = Más bajo

Sibsp: el conjunto de datos define las relaciones familiares de esta manera ...
Hermano = hermano, hermana, hermanastro, hermanastra
Cónyuge = esposo, esposa (las amantes y los novios fueron ignorados)

Parch: El conjunto de datos define las relaciones familiares de esta manera ...
Padre = madre, padre
Niño = hija, hijo, hijastra, hijastro
Algunos niños viajaban solo con una niñera, por lo tanto parch = 0 para ellos.

## 2. Integración y selección
__Integración y selección de los datos de interés a analizar.__

Inicialmente hare un al tratar de unir las 2 bases de datos (train y test), y para hacer un vistazo genereal de como estan los datos, no he podido porque el archivo train tiene 12 variables y el test 11 variables, la variable que diferencia es Survived.

He tomado la decisón de responder ¿Podria llegarse a determinar si los pasajeros que estan en el dataset test si sobrevivieron o no, basandome en los datos de entrenamiento?

```{r train}
#setwd("C:/Users/Admin/Dropbox/Master/Tipologia de Datos/PRACTICA 2")
train <- read.csv2("train.csv",header = TRUE,sep = ";",dec = ".",stringsAsFactors=FALSE)
cat(paste0("Carga fichero train.csv OK.","\n\n"))
str(train)
```

```{r test}
test <- read.csv2("test.csv",header = TRUE,sep = ";",dec = ".")
cat(paste0("Carga fichero test.csv OK.","\n\n"))
str(test)
```

Variables Categoricales: Survived, Sex, and Embarked. Ordinal: Pclass.

Variables Continuas: Age, Fare. Discrete: SibSp, Parch

He unido los dos dataset (train y test) para pode trabajar con ellos de manera mas sencilla, pero como el dataset test no tiene la variable Survived, he creado la columna "Survived" y la he llenado con NA

```{r}
test$Survived <- NA
titanic <- rbind(train,test)
summary(titanic)
```

```{r}
titanic$Name <- as.factor(titanic$Name)
titanic$Sex <- as.factor(titanic$Sex)
titanic$Ticket <- as.factor(titanic$Ticket)
titanic$Embarked <- as.factor(titanic$Embarked)

summary(titanic)
```

## 3. Limpieza de los datos

### 3.1. Ceros y elementos vacíos

¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Hay 263 datos __NA__ en la variable Age, hay 418 NA en la variable __Survived__, que son los valores que anteriormente adicione del dataset test.
La variable __Fare__ debe ser numerica y se encuentra como factor, la he convertido en numerica.

```{r}
titanic$Fare <- as.numeric(titanic$Fare)

cat(paste0("Valores vacios Age ",round((263/1309)*100,2)),"%")
cat("\n\n")

cat(paste0("Valores vacios Fare ",round((36/1309)*100,2)),"%")
cat("\n\n")

# Para aquellos pasajeros que se desconoce la cabina, se le cambia su vacio  por un string que indica desconocido
titanic$Cabin[titanic$Cabin==""] <- "Unknown"
titanic$Cabin <- as.factor(titanic$Cabin)

# Hay 2 pasajeros en la columna Embarked que estan vacios y la mayoria embarco por S entonces lo he agregardo alli.
errores = which(titanic$Embarked=="")
titanic$Embarked[errores] = "S"
titanic$Embarked <- factor(titanic$Embarked)

# Números de valores desconocidos por campo
sapply(titanic, function(x) sum(is.na(x)))
rm(errores)
```

Para manejar los registros que contienen valores desconocidos para algún campo, una opción podría ser eliminar los registros que incluyen este tipo de valores de la variable Age, pero ello supondría desaprovechar el 20.09% de esta información y para la varaible Fare quitar los NA upondría desaprovechar el 2.75% de esta información

Se empleará el método para imputa de una manera sofisticada para que no toda la matriz de distancia tenga que calcularse: la imputación basada en k vecinos más próximos (en inglés, kNN-imputation). Por lo tanto, la implementación del paquete VIM también es aplicable para conjuntos de datos razonablemente grandes

Como tengo 12 datos en donde la variable Age son números inferiores a 1, por lo tanto he decido multiplicar estos datos por 100, ya que considero que ha sido un error de digitación y no quisiera perderlos, he hecho esto antes de la imputación.

```{r imputacion}
#Cambio las observaciones <1 y las multiplico por 100 y luego las vuelvo a unir a titanic
edad_aux <- filter(titanic, titanic$Age<1)
edad_aux$Age <- edad_aux$Age*100
titanic <- dplyr::full_join(titanic,edad_aux) 
titanic <-arrange(titanic, PassengerId)
rm(edad_aux)
# Imputación de valores mediante la función kNN() del paquete VIM
suppressWarnings(suppressMessages(library(VIM)))

titanic$Age <- kNN(titanic)$Age
titanic$Fare <- kNN(titanic)$Fare

sapply(titanic, function(x) sum(is.na(x)))

summary(titanic)
```

```{r}
#   Listo el preprocesado del dataset, separo en train y test 
train <- titanic[1:891,]
test <- titanic[892:1309,]
#Quitamos la columna Survived de test usada para unir los datos
test$Survived = NULL
```

### 3.2. Valores extremos
__Identificación y tratamiento de valores extremos__

Los valores extremos o outliers son aquellos que parecen no ser congruentes sin los comparamos con el resto de los datos.

```{r}
ggpairs(train[c(2,3,6,7,8,10)])
```

```{r}
#gráfico la variable Age, sin NA y valores <1 corregidos
ggplot(train, aes(x = Age)) +
    geom_histogram(fill = "darkblue", alpha = .5) +
    geom_histogram(colour = "black")+
    facet_wrap(~ Survived)
```

```{r}
boxplot.stats(train$Age)$out
```

```{r}
#gráfico la variable Fare
ggplot(train, aes(x = Fare)) +
    geom_histogram(fill = "darkblue", alpha = .5) +
    geom_histogram(colour = "black")+
    facet_wrap(~ Survived)
```

```{r}
boxplot.stats(train$Fare)$out
```

```{r}
p <- ggplot(train, aes(x=Survived, y=Age,fill=Survived)) + 
    geom_boxplot() 
q <- ggplot(train, aes(x=Survived, y=Fare,fill=Survived)) + 
    geom_boxplot() 

grid.arrange(p,q,ncol = 2)
```


Otras variables númericas que se utilizan en el problema.

```{r}
# La cantidad de personas en cada clase
p <- ggplot(train, aes(x=Pclass)) + 
  geom_histogram()

# La edad de las personas
q <- ggplot(train, aes(x=Age)) + 
  geom_histogram()

# La cantidad hermanos/conyuges de la personas
r <- ggplot(train, aes(x=SibSp)) + 
  geom_histogram()

# La cantidad de parientes y niños abordo 
s <- ggplot(train, aes(x=Parch)) + 
  geom_histogram()

# La tarifas de los tickets por personas
t <- ggplot(train, aes(x=Fare)) + 
  geom_histogram()

grid.arrange(p,q,r,s,t,ncol = 2)
```

## 4. Análisis de los datos.

### 4.1. Selección de los grupos de datos a analizar
__Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)__

```{r}
#Analisis de superviviencia
#   Con el caso de los sobrevientes o no
ggplot(train, aes(x=Survived)) + 
  geom_histogram()

table(as.factor(train$Survived)) #  Cantidades en una tabla
```

Podemos observar que alrededor del 55.45% no sobrevivio y el 44.55% sobrevivio.

### 4.2. Normalidad
__Comprobación de la normalidad y homogeneidad de la varianza.__

Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población con distribución normal, utilizaremos la prueba de normalidad de Anderson-Darling.

Con esto, comprobaremos que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado $\alpha = 0, 05$. Si esto se cumple, entonces se considera que la variable se distribuye normalmente.

```{r}
library(nortest)
alpha = 0.05
col.names = colnames(train)
for (i in 1:ncol(train)) {
    if (i == 1) cat("Variables que no se distribuyen normalmente:\n")
    if (is.integer(train[,i]) | is.numeric(train[,i])) {
        p_val = ad.test(train[,i])$p.value
        if (p_val < alpha) {
            cat(col.names[i])
            # Format output
    if (i < ncol(train) - 1) cat(", ")
        }
    }
}
```

```{r}
fligner.test(Age ~ Survived, data = train)
```

Obtenemos un p-valor superior a 0,05, aceptamos la hipótesis de que las varianzas de ambas muestras son homogéneas.

### 4.3. Pruebas Estadísticas
__Aplicación de pruebas estadísticas para comparar los grupos de datos__

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc.

Ahora poseemos un mejor conocimiento de los elementos y atributos de las variables, pero esta no nos dicen la manera en que se relacionan. Para ello apliacaremos un analisis de componentes principales al conjunto de datos.

```{r, message=FALSE, warning=FALSE}
#   Observemos el Analisis de Componentes Principales (ACP) de las variables cuantitativas
cuant <- data.frame(
    train$Survived,train$Pclass,train$Age,train$Parch,train$SibSp,train$Fare)
train.pca <- pca(cuant)
train.pca
```

Obtenido el PCA, observemos claramente la correlación de las variables:

```{r}
#   Viendo las correlaciones de las variables involucradas en el PCA, procedemos
#   a ver aquellas variables que parecieran tener alguna relacion entre si
M <- cor(cuant)
round(M,2)
```

Podemos observar que entre las variables cuantitativas, hay una serie de resultados interesantes:

* Existe una correlacion negativa significativa entre la clase en la que abordo el pasajero y su tarifa y su supervivencia. Esto se explica dado que las personas de primera clase pagaban una tarifa mucho mayor por abordar y tambien podemos decir que la mayoria de las personas al ser menor la cantidad de personas en primera clase con respecto a las otras dos, estos tenian una mayor posibilidad de sobrevivir, mientras que la segunda y la tercera clase ocurre lo contrario. 

```{r}
#   Con respecto al Sexo de las personas podemos ver la siguiente distribucion
table(train$Sex)
```

Vemos que habian 313 mujeres y 578 hombres lo que representa un 35,13% de mujeres y un 64,87% de hombres en el conjunto de entrenamiento. Ahora relacionemos esta información con la sobrevivencia de los pasajeros y tambien la tasa de sobrevivencia de los niños.

```{r}
#   Siguiendo el contexto del problema examinemos el sexo de los sobrevivientes
table(train$Sex,train$Survived)
Surv_age <- ifelse(train$Age<=18,"Niño","Adulto") 
table(Surv_age,train$Survived)
table(Surv_age,train$Survived, by=train$Sex) # Sobrevivieron mas niñas que niños
```

Ahora comparemos usando arboles decision como metodo para generar un modelo predictivo.

```{r}
#   Tomamos un subconjunto de los mismos
training <- subset(train,select=-c(PassengerId,Name,Ticket,Cabin))
modelo_arbol <- rpart(Survived ~ ., data=training,method="class")

prediction <- predict(modelo_arbol,training[,-1])
prediction <- ifelse(prediction<0.5,0,1)
matriz_conf <- table(prediction = prediction[,2], true = training[,1])
matriz_conf
```

De acuerdo a la matriz de confusión tenemos el mismo indice de acierto y de desacierto que teniamos inicialmente, con una pequeña variacion entre falsos positivos y falsos negativos. 

## 5. Visualización
__Representación de los resultados a partir de tablas y gráficas__

```{r}
#acp
# autoplot(prcomp(cuant))
train$Survived <- as.factor(train$Survived)
autoplot(prcomp(cuant), data = train, colour = 'Survived',
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 3)

 train.pca2 <- prcomp(cuant,scale.=TRUE)
 g<-ggbiplot(train.pca2, obs.scale=1, var.scale=1,  ellipse=TRUE, circle=TRUE)
 g<-g+scale_color_discrete(name="")
 print(g)

#Correlación
corrplot.mixed(M, lower.col = "black", number.cex = .7)

#arbol de decisión
rpart.plot(modelo_arbol)

```

Las variables Survived y Fare estan altamente correlacionadas.

## 6. Resolución del problema. 

A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?



## 7. Código

Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.

\newpage

#8. Referencias

Los siguientes recursos son de utilidad para la realización de la práctica:

- Megan Squire (2015). Clean Data. Packt Publishing Ltd.
- Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann
- Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369
- Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media
- Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc
- Tutorial de Github "https://guides.github.com/activities/hello-world"
- Ejemplos de contrastes de hipótesis con R:  " https://rstudio-pubs-static.s3.amazonaws.com/65042_a1784120e81a430f9de400ed9b899b0b.html"
- Tutorial dplyr:  "https://github.com/fdelaunay/tutorial-dplyr-es/blob/master/R/tutorial-dplyr.md"
- Test de Shapiro-Wilk:  "https://rpro.wikispaces.com/Test+de+Shapiro-Wilk"
- Estadística descriptiva: "Introducción al análisis de datos", Àngel J. Gil Estallo
- Intervalos de confianza, Àngel J. Gil Estallo
- Contrastes de hipótesis, Carles Rovira Escofet
- Contraste de dos muestras, Josep Gibergans Bàguena                                      
